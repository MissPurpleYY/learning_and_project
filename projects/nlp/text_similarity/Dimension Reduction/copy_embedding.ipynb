{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "falling-shelter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "dataset = tf.data.TextLineDataset(\n",
    "    filenames='/home/fkovalev/reviews_filtered.txt', compression_type=None, buffer_size=None, num_parallel_reads=None\n",
    ")\n",
    "dataset = dataset.take(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "medical-shopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitter(line):\n",
    "    segs = tf.strings.split(line)\n",
    "    return {'review_id':segs[0], 'text':segs[-1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "worthy-textbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted_dataset = dataset.map(\n",
    "    lambda line: splitter(line),\n",
    "    num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "confused-seminar",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2048\n",
    "batches = splitted_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "together-virtue",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fifteen-hobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(batch):\n",
    "    review_ids = batch['review_id']\n",
    "    embeddings = embed(batch['text'])\n",
    "    original_text = batch['text']\n",
    "    return {'review_id': review_ids, 'text': original_text,'use_vector': embeddings}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "indirect-wednesday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ParallelMapDataset shapes: {review_id: (None,), text: (None,), use_vector: (None, 512)}, types: {review_id: tf.string, text: tf.string, use_vector: tf.float32}>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = batches.map(\n",
    "    lambda batch: inference(batch),\n",
    "    num_parallel_calls=48,\n",
    "    deterministic=False\n",
    ")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "linear-stream",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'3872002725\\tpositive\\tPerfect plan B for our beach wedding that we couldn\\xe2\\x80\\x99t have.', shape=(), dtype=string)\n",
      "tf.Tensor(b'3872002725\\tpositive\\tStaff were AMAZING - so friendly and accommodating.', shape=(), dtype=string)\n",
      "tf.Tensor(b'3872006069\\tpositive\\tAll apartments with a pool view Ten minute walk to the centre of town, very friendly, helpful and flexible staff and good clean rooms and comfy beds', shape=(), dtype=string)\n",
      "tf.Tensor(b'3872009990\\tpositive\\tWe had a 2 bedroom suite with a hot tub.', shape=(), dtype=string)\n",
      "tf.Tensor(b'3872009990\\tpositive\\tVery private setting and great atmosphere.', shape=(), dtype=string)\n",
      "tf.Tensor(b'3872013970\\tpositive\\tOverall the room was very clean, as were the bathrooms.', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for element in dataset.take(6):\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "knowing-turtle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 512])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = [\"Staff were AMAZING - so friendly and accommodating.\"]\n",
    "query_vec = embed(query) #encodes the string in the list\n",
    "query_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "blocked-orientation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: {review_id: (None,), text: (None,), use_vector: (None, 512)}, types: {review_id: tf.string, text: tf.string, use_vector: tf.float32}>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "sitting-enemy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review_ids:  [[b'3872002725']\n",
      " [b'3872002725']\n",
      " [b'3872006069']\n",
      " [b'3872009990']\n",
      " [b'3872009990']]\n",
      "text:  [[b'have.']\n",
      " [b'accommodating.']\n",
      " [b'beds']\n",
      " [b'tub.']\n",
      " [b'atmosphere.']]\n"
     ]
    }
   ],
   "source": [
    "for r in results.take(1):\n",
    "    #vectors = r['use_vector'].numpy()\n",
    "    print('review_ids: ',r['review_id'].numpy()[...,None])\n",
    "    print('text: ', r['text'].numpy()[...,None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "painted-constraint",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'itemgetter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-cf76355798d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mcorrelation_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrelation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mscore_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrelation_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtop_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mitemgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'itemgetter' is not defined"
     ]
    }
   ],
   "source": [
    "correlation_table = []\n",
    "top_k = 5\n",
    "for result in results:\n",
    "    review_ids = result['review_id'].numpy()[...,None]\n",
    "    vectors = result['use_vector'].numpy()\n",
    "    review = result['text'].numpy()\n",
    "    correlation = np.transpose(np.inner(query_vec,vectors))\n",
    "    correlation_table.append(correlation)\n",
    "score_table = zip(review_ids, correlation_table)\n",
    "top_results = sorted(score_table, key= itemgetter(1), reverse = True)[0:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colored-concrete",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "with open('/yueyang/reviews_filtered_use.emb', 'a', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    step = 0\n",
    "    st_time = time.time()\n",
    "    for result in results:\n",
    "        if (step+1)%100 == 0:\n",
    "            ed_time = time.time()\n",
    "            print('{} s/step'.format((ed_time-st_time)/100))\n",
    "            st_time = ed_time\n",
    "        bytes_2_str = lambda x:x.decode(\"utf-8\") \n",
    "        review_ids = result['review_id'].numpy()[...,None]\n",
    "        vectors = result['use_vector'].numpy()\n",
    "        concat = np.concatenate((review_ids, vectors), axis=1)\n",
    "        writer.writerows(concat)\n",
    "        step += 1\n",
    "        if step == 200:\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
